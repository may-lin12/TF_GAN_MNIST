{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        \n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d1 = d1 + d_b1\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "\n",
    "        # d4 contains unscaled values\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    # From z_dim to 56*56 dimension\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" See the fake image we make \"\"\"\n",
    "\n",
    "# Define the plceholder and the graph\n",
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "\n",
    "# For generator, one image for a batch\n",
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output,\n",
    "                                feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')\n",
    "    plt.savefig(\"test_img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#需要在每個單獨步驟前面加入 tf.reset_default_graph() 來確保每次都是重新使用新的 graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "batch_size=32\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder) \n",
    "# Dx will hold discriminator prediction probabilities\n",
    "# for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two Loss Functions for discriminator\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "\n",
    "# Loss function for generator\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_w2:0', 'g_b2:0', 'g_w3:0', 'g_b3:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "# Get the varaibles for different network\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\" For setting TensorBoard \"\"\"\n",
    "\n",
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0回-- dLossReal: 0.691919 dLossFake: 0.715515\n",
      "第20回-- dLossReal: 0.571425 dLossFake: 0.800668\n",
      "第40回-- dLossReal: 0.440638 dLossFake: 0.875038\n",
      "第60回-- dLossReal: 0.294202 dLossFake: 0.526869\n",
      "第80回-- dLossReal: 0.0733301 dLossFake: 0.14\n",
      "第100回-- dLossReal: 0.00311538 dLossFake: 0.00756998\n",
      "第120回-- dLossReal: 0.00130517 dLossFake: 0.00196251\n",
      "第140回-- dLossReal: 0.000446076 dLossFake: 0.0011177\n",
      "第160回-- dLossReal: 0.000622296 dLossFake: 0.00104515\n",
      "第180回-- dLossReal: 0.000490728 dLossFake: 0.000924832\n",
      "第200回-- dLossReal: 0.000414739 dLossFake: 0.000907677\n",
      "第220回-- dLossReal: 0.000610627 dLossFake: 0.000924609\n",
      "第240回-- dLossReal: 0.000521931 dLossFake: 0.000839957\n",
      "第260回-- dLossReal: 0.000791013 dLossFake: 0.000787666\n",
      "第280回-- dLossReal: 0.000576586 dLossFake: 0.00079388\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start Training Session \"\"\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "list1 = []\n",
    "list2 = []\n",
    "list3 = [] \n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(300):\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    if(i % 20 == 0):\n",
    "        print(\"第\"+str(i)+\"回--\",\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)           \n",
    "        list1.append(i)\n",
    "        list2.append(dLossReal)\n",
    "        list3.append(dLossFake)\n",
    "        \n",
    "        #print (list1)\n",
    "        #print (list2)\n",
    "        #print (list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABCCAYAAABHNy1XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b0d46c3f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dLossReal\n",
    "def plotData(plt, data):\n",
    "  x = list1\n",
    "  y = list2\n",
    "  plt.plot(x, y, '-o')\n",
    "\n",
    "plotData(plt, list2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b0d5e0c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dLossFake\n",
    "def plotData1(plt, data):\n",
    "  x = list1\n",
    "  y = list3\n",
    "  plt.plot(x, y, '-o')\n",
    "\n",
    "plotData(plt, list3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: tmp/model0.ckpt\n",
      "Iteration: 0 at 2018-09-24 03:33:21.409692\n",
      "Estimate: [[-7.18876696]]\n",
      "Iteration: 100 at 2018-09-24 03:36:19.646777\n",
      "Estimate: [[-6.99517393]]\n",
      "Iteration: 200 at 2018-09-24 03:39:13.765751\n",
      "Estimate: [[-8.17870903]]\n",
      "Iteration: 300 at 2018-09-24 03:42:08.790693\n",
      "Estimate: [[-9.328578]]\n",
      "Iteration: 400 at 2018-09-24 03:44:59.311340\n",
      "Estimate: [[-9.15846062]]\n",
      "Iteration: 500 at 2018-09-24 03:47:49.842157\n",
      "Estimate: [[-9.78022194]]\n",
      "Iteration: 600 at 2018-09-24 03:50:44.172336\n",
      "Estimate: [[-9.06310272]]\n",
      "Iteration: 700 at 2018-09-24 03:53:36.710994\n",
      "Estimate: [[-11.55743408]]\n",
      "Iteration: 800 at 2018-09-24 03:56:30.967837\n",
      "Estimate: [[-10.74424744]]\n",
      "Iteration: 900 at 2018-09-24 03:59:26.960949\n",
      "Estimate: [[-9.53904057]]\n"
     ]
    }
   ],
   "source": [
    "# Train generator and discriminator together\n",
    "for i in range(1000):\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "   # Train discriminator on both real and fake images\n",
    "    _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                           {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    # Train generator\n",
    "    z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "    # if i % 10 == 0:\n",
    "    #     # Update TensorBoard with summary statistics\n",
    "    #     z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "    #     summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "    #     writer.add_summary(summary, i)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        # Save the model every 1000 iteration\n",
    "        save_path = saver.save(sess, \"tmp/model{}.ckpt\".format(i))\n",
    "        print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # Every 100 iterations, show a generated image\n",
    "        print(\"Iteration:\", i, \"at\", datetime.datetime.now())\n",
    "        z_batch = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "        generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "        images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "        plt.imshow(images[0].reshape([28, 28]), cmap='Greys')\n",
    "        plt.savefig(\"img/image{}.png\".format(i))\n",
    "\n",
    "        # Show discriminator's estimate\n",
    "        im = images[0].reshape([1, 28, 28, 1])\n",
    "        result = discriminator(x_placeholder)\n",
    "        estimate = sess.run(result, {x_placeholder: im})\n",
    "        print(\"Estimate:\", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
